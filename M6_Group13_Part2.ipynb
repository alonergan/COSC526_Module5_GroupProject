{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654f0f06",
   "metadata": {},
   "source": [
    "# M6 Team Assignment: Spooky Authorship With Spark Part 2\n",
    "\n",
    "#### Group 13\n",
    "- Aidan Lonergan\n",
    "- Daniel Lillard\n",
    "- Radhika Garg\n",
    "- Claudine Uwiragiye\n",
    "\n",
    "## Objective\n",
    "- In this assignment, your team will improve your scores from the first Spooky Authorship assignment. Your goal should be to get at least a 80% accuracy. If you already have over 80% accuracy, aim to get 85% accuracy. \n",
    "\n",
    "### Team Objectives\n",
    "- Initially we tried to improve the accuracy of our Multilayer Perceptron Classifier, but after hours of cross validations and numerous revisions to the preprocessing, we could not surpass 72% test accuracy with that algorithm. Lemmatization did not help this model for some reason\n",
    "- We decided to completely revamp the preprocessing and try to improve NaiveBayes which performed the second best originally, this proved to be much easier and tuneable when adding lemmatization.\n",
    "    - Lemmatizing with POS (Part of speech) helped improve the accuracy greatly\n",
    "    - Unlike the MLP, increasing the hashing tf numFeatures improved accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142fb90",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Stage 0 - Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3501cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 0 Solution\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Start spark session and load train and test data sets\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Module_5_Project\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .config(\"spark.python.worker.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.pyspark.memory\", \"2g\") \\\n",
    "    .config(\"spark.rpc.io.connectionTimeout\", \"30s\") \\\n",
    "    .config(\"spark.default.parallelism\", \"16\") \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .config(\"spark.task.cpus\", \"1\") \\\n",
    "    .config(\"spark.driver.host\",\"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_train = spark.read.csv('./train.csv', header=True, inferSchema=True, quote='\"', escape='\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd86d2d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Stage 1 - Data Preparation\n",
    "- Originally we had removed punctuation, stop words, and did not do lemmatization. After redoing the preprocessing to only do lemmatization this greatly increased the accuracy\n",
    "- It's possible that either identifying information was removed through the excessive preprocessing, or combining lemmatization and other steps removed information.\n",
    "- Either way we decided to keep it simple and go with what performed best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aflon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Error loading own-1.4: Package 'own-1.4' not found in\n",
      "[nltk_data]     index\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aflon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aflon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Preprocessing\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download nltk resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('own-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# 'Switch' function for returing the POS tag\n",
    "def pos_switch(tag):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "# Lemmatizes the input text with POS (Part of speech)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    # Tokenize words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Get POS tag for tokens\n",
    "    tags = pos_tag(words)\n",
    "\n",
    "    # Lemmatize based on token and tag\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word, pos_switch(pos)) for word, pos in tags]\n",
    "    return \" \".join(lemmatized_text)\n",
    "\n",
    "# Convert to Pandas DataFrame temporarily. Had immense issues with PySpark UDFs and worker timeouts. This just makes it simple\n",
    "df_tmp = df_train.toPandas()\n",
    "\n",
    "# Lemmatize text into new column\n",
    "df_tmp[\"processed_text\"] = df_tmp[\"text\"].apply(lemmatize_text)\n",
    "\n",
    "# Convert back to Spark DataFrame\n",
    "df_lemmatized = spark.createDataFrame(df_tmp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2115d8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Stage 2 - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2511d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(524288,[8732,19036,20901,38308,91767,100941,117491,131709,141331,145207,148880,167503,214862,219087,248200,261675,289720,293094,296332,307548,309043,312145,350734,351861,358033,364180,369251,370685,404383,445483,446082,448456,471662,482059,483171,499532,503088,518612],[7.397357266296501,2.036730623534044,3.108592115558026,4.405800364152991,6.271346003440277,7.243206586469243,2.6495307799068866,4.2987676073028025,1.1219589976525253,0.5407198584929742,4.261863050367351,4.706114183510672,6.448276711599355,1.611653523768082,6.704210085736555,4.16523621467828,0.8152167139347949,1.425457874683359,5.839212648249951,0.044969586283172255,5.427916619830993,2.072722591431091,6.550059405909297,3.048155177270663,1.2477762646451427,6.271346003440277,0.7931876316013579,2.0739408656934453,4.007333185232471,3.99061970425873,3.332613173850691,2.5505489463580355,4.706114183510672,0.5701795602250346,7.579678823090456,3.4114644123018993,1.60918258241867,3.5055369681858743])|\n",
      "|(524288,[17046,39275,113673,145207,277457,289720,293094,307548,310592,312145,358033,369251,383545,514987,518612],[5.77139005191119,7.802822374404665,3.6075018948425623,0.5407198584929742,5.382454245754237,0.8152167139347949,1.425457874683359,0.044969586283172255,1.3425267602333695,2.072722591431091,0.31194406616128567,0.7931876316013579,5.0619823504794645,3.8636707015882665,3.5055369681858743])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|(524288,[4106,48648,49120,98424,102006,126466,141331,145207,219087,224255,227860,284514,287361,290482,296004,304548,307548,317783,324934,337436,358033,363313,369251,375091,405346,432558,461320,494511,501487,507667,512999,523989,524014],[4.764270103667746,5.146065467690006,1.9229879559681051,4.376932380152138,5.349664422931245,1.6602474788823054,1.1219589976525253,0.5407198584929742,1.0744356825120547,3.580660920209216,4.912450616508501,5.349664422931245,3.7932190406376556,7.802822374404665,1.8967795593506789,2.347501259046964,0.044969586283172255,3.3885100762328153,4.667328158475516,6.663388091216301,0.6238881323225713,2.041557464335102,1.5863752632027157,15.370078677496563,2.458098635042473,5.349664422931245,6.326915854595088,3.7641667180431533,0.0,4.564143922240285,1.014132202581468,5.6926091740580755,3.434958053543288])                                                                                                                                      |\n",
      "|(524288,[4181,67416,99179,141331,145207,161773,168342,189996,195453,199693,206227,209164,216689,270873,294536,304548,307548,324544,358033,363313,369251,374496,418228,428950,445555,459587,460733,471280,482059,483459,485907,501167,512999,521193],[5.382454245754237,2.1463935961319347,4.678257229007706,0.841469248239394,0.5407198584929742,6.88653164253051,5.439612659594185,5.209435081622595,0.0,2.057018624652727,5.633768674035142,6.746769700155352,5.591804474936111,6.991892158188337,5.6926091740580755,2.347501259046964,0.044969586283172255,5.475544668820248,0.31194406616128567,2.041557464335102,0.7931876316013579,3.9033781511833796,2.608477598239607,6.991892158188337,5.070079560712084,3.9394645409578004,3.442913544984403,7.484368643286131,1.1403591204500692,3.8348917370382236,7.101524132381621,8.272826003650401,1.014132202581468,4.926436858483241])                                                                                                                |\n",
      "|(524288,[20901,33917,37673,49120,56194,64760,66221,67562,116996,128076,141331,174966,187114,224255,236309,255882,296338,307548,334519,358033,368093,369251,415567,441976,483837,485907,523989],[1.554296057779013,1.8151148761743958,7.579678823090456,5.768963867904315,4.700480365792417,7.802822374404665,6.448276711599355,5.578198822880331,4.215837227972069,4.947789982953809,0.5609794988262626,3.307188075484881,1.9177605525329535,1.790330460104608,6.168691849380194,6.550059405909297,7.579678823090456,0.044969586283172255,7.685039338748282,0.31194406616128567,5.045982009133024,1.5863752632027157,3.6226824520195784,3.548984287944811,1.8544610677141897,3.5507620661908104,5.6926091740580755])                                                                                                                                                                                                                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "# Define stages for pipeline [Tokenization -> TF -> IDF]\n",
    "tokenizer = Tokenizer(inputCol=\"processed_text\", outputCol=\"tokens\")            # Converts the pos lemmatized text into tokens\n",
    "hashingTF = HashingTF(inputCol='tokens', outputCol='tf', numFeatures=524288)    # Computes a hashing TF on the tokens. 524288 has the highest accuracy, going higher reduced it\n",
    "idf = IDF(inputCol='tf', outputCol='features', minDocFreq=3)                    # Computes an IDF on the hashing TF output\n",
    "\n",
    "\n",
    "# Define pipeline with all stages\n",
    "nb_pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "\n",
    "# Execute the pipeline with the pos lemmatized text and transform to tfidf\n",
    "tfidf = nb_pipeline.fit(df_lemmatized).transform(df_lemmatized)\n",
    "tfidf.select(\"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d43d1c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Stage 3 - Machine Learning\n",
    "1) Perform 80/20 train/test split\n",
    "2) Train Naive Bayes to achieve >80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b5d62bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8404924044002096\n",
      "Test F1 Score: 0.8405433503346229\n",
      "Best smoothing parameter: 1.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Convert authors to numerical labels\n",
    "indexer = StringIndexer(inputCol=\"author\", outputCol=\"label\")\n",
    "df_labeled = indexer.fit(tfidf).transform(tfidf)\n",
    "\n",
    "# Do a 80/20 split for validations\n",
    "df_train, df_test = df_labeled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Setup model and evaluators\n",
    "naive_bayes = NaiveBayes()\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "# Setup hyper param to test, here we're just adjusting the smoothing for NB\n",
    "params = ParamGridBuilder().addGrid(\n",
    "    naive_bayes.smoothing, [0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5]\n",
    "    ).build()\n",
    "\n",
    "# Set cross validator params\n",
    "cv = CrossValidator(\n",
    "    estimator=naive_bayes, \n",
    "    estimatorParamMaps=params, \n",
    "    evaluator=accuracy_evaluator, \n",
    "    parallelism=8\n",
    "    )\n",
    "\n",
    "# Train the cross validator to find the best model\n",
    "model = cv.fit(df_train)\n",
    "best_model = model.bestModel\n",
    "\n",
    "# Predict on the test set\n",
    "nb_prediction = best_model.transform(df_test)\n",
    "\n",
    "# Evaluate \n",
    "print('Test Accuracy:', accuracy_evaluator.evaluate(nb_prediction))\n",
    "print('Test F1 Score:', f1_evaluator.evaluate(nb_prediction))\n",
    "print(f'Best smoothing parameter: {best_model.getSmoothing()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e390f0f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Stage 4 - Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd494c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkAttributeError",
     "evalue": "[ATTRIBUTE_NOT_SUPPORTED] Attribute `labels` is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPySparkAttributeError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m label_mapping = \u001b[43mdf_labeled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabels\u001b[49m  \u001b[38;5;66;03m# Get mapping of indices to author names for analysis (e.g., ['EAP', 'HPL', 'MWS'])\u001b[39;00m\n\u001b[32m      6\u001b[39m test_data_nn = df_test.drop(\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m nb_test_predictions = best_model.transform(test_data_nn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aflon\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\classic\\dataframe.py:971\u001b[39m, in \u001b[36mDataFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Column:\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkAttributeError(\n\u001b[32m    972\u001b[39m             errorClass=\u001b[33m\"\u001b[39m\u001b[33mATTRIBUTE_NOT_SUPPORTED\u001b[39m\u001b[33m\"\u001b[39m, messageParameters={\u001b[33m\"\u001b[39m\u001b[33mattr_name\u001b[39m\u001b[33m\"\u001b[39m: name}\n\u001b[32m    973\u001b[39m         )\n\u001b[32m    974\u001b[39m     jc = \u001b[38;5;28mself\u001b[39m._jdf.apply(name)\n\u001b[32m    975\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[31mPySparkAttributeError\u001b[39m: [ATTRIBUTE_NOT_SUPPORTED] Attribute `labels` is not supported."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "test_data_nb = df_test.drop('author')\n",
    "nb_test_predictions = best_model.transform(test_data_nb)\n",
    "\n",
    "nb_evaluator = MulticlassClassificationEvaluator(labelCol='author', predictionCol='prediction', metricName='f1')\n",
    "acc_score = nb_evaluator.evaluate(nb_test_predictions)\n",
    "print(f\"Naive Bayes Accuracy Score: {acc_score}\")\n",
    "\n",
    "# Get confusion matrix\n",
    "nb_test_predictions = nb_test_predictions.select('author', 'prediction').toPandas()\n",
    "nb_conf_mat = confusion_matrix(nb_test_predictions['author'], nb_test_predictions['prediction'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(nb_conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping, yticklabels=label_mapping)\n",
    "plt.title(\"Naive Bayes Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Author\")\n",
    "plt.ylabel(\"True Author\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
